{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095816da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from langchain_qdrant import QdrantVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61cacc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e074b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SECONDARY_SPLIT = False   \n",
    "CHUNK_SIZE = 256\n",
    "CHUNK_OVERLAP = 30\n",
    "HEADERS_TO_SPLIT = [(\"#\", \"H1\"), (\"##\", \"H2\"), (\"###\", \"H3\")]                               # Number of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152100aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_markdown(text: str):\n",
    "    splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=HEADERS_TO_SPLIT,\n",
    "        strip_headers=False,   # keep headings inside the chunk text\n",
    "    )\n",
    "    docs = splitter.split_text(text)\n",
    "    if USE_SECONDARY_SPLIT and len(docs) == 1:\n",
    "        char_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n",
    "        )\n",
    "        docs = char_splitter.split_documents(docs)\n",
    "    return docs\n",
    "\n",
    "def process_markdown_directory(in_dir: str, qdrant_dir: str, collection: str):\n",
    "    \"\"\"Main function to process markdown files and store them into a local Qdrant vector database.\"\"\"\n",
    "    \n",
    "    in_dir = Path(in_dir)\n",
    "    qdrant_dir = Path(qdrant_dir)\n",
    "\n",
    "    # 1) Collect & split\n",
    "    all_docs = []\n",
    "    counts = defaultdict(int)\n",
    "    for md_path in in_dir.rglob(\"*.md\"):\n",
    "        text = md_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        docs = split_markdown(text)\n",
    "        for d in docs:\n",
    "            d.metadata = {\"source\": md_path.as_posix(), **(d.metadata or {})}\n",
    "        all_docs.extend(docs)\n",
    "        counts[md_path.as_posix()] += len(docs)\n",
    "\n",
    "    print(f\"Collected {len(all_docs)} chunks from {len(counts)} files.\")\n",
    "\n",
    "    # 2) Embeddings\n",
    "    embeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "\n",
    "    # 3) Local embedded Qdrant (persists under qdrant_dir)\n",
    "    qdrant_dir.mkdir(parents=True, exist_ok=True)\n",
    "    client = QdrantClient(path=str(qdrant_dir))\n",
    "\n",
    "    # 4) Create collection if missing (size must match embedding dim)\n",
    "    vector_size = len(embeddings.embed_query(\"sample text\"))\n",
    "    try:\n",
    "        client.get_collection(collection_name=collection)\n",
    "    except Exception:\n",
    "        client.create_collection(\n",
    "            collection_name=collection,\n",
    "            vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE),\n",
    "        )\n",
    "\n",
    "    # 5) Upsert via LangChain QdrantVectorStore\n",
    "    store = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection,\n",
    "        embedding=embeddings,\n",
    "    )\n",
    "    store.add_documents(all_docs)\n",
    "\n",
    "    print(f\"Qdrant local DB ready at: {qdrant_dir} | collection: {collection}\")\n",
    "\n",
    "    # Simple per-file stats\n",
    "    print(\"\\nChunks per file (desc):\")\n",
    "    for src, c in sorted(counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{c:5d}  {src}\")\n",
    "    total = sum(counts.values())\n",
    "    avg = total / len(counts) if counts else 0\n",
    "    print(f\"\\nFiles: {len(counts)} | Total chunks: {total} | Avg/file: {avg:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9755f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 chunks from 1 files.\n"
     ]
    }
   ],
   "source": [
    "process_markdown_directory(\n",
    "    in_dir=\"1\",\n",
    "    qdrant_dir=\"stores/qdrant_db_test_1\",\n",
    "    collection=\"rag_chunks_test\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
