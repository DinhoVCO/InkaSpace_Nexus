{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "222183dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json # Importar el módulo JSON\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87fffaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html_from_file(file_path: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Lee el contenido de un archivo HTML desde una ruta específica.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al leer el archivo '{file_path}': {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_project_data(row, pi_name, last_updated):\n",
    "    \"\"\"\n",
    "    Extrae la información detallada de una única fila, incluyendo\n",
    "    datos bibliográficos como DOI, PMID y título.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        # --- Datos del Proyecto ---\n",
    "        project_cell = cells[1]\n",
    "        project_link_tag = project_cell.find('a', href=re.compile(\"TASKID\"))\n",
    "        project_name = project_link_tag.get_text(strip=True)\n",
    "        relative_link = project_link_tag['href']\n",
    "        project_link = f\"https://taskbook.nasaprs.com/tbp/{relative_link}\"\n",
    "        task_id_match = re.search(r'TASKID=(\\d+)', relative_link)\n",
    "        task_id = task_id_match.group(1) if task_id_match else \"No encontrado\"\n",
    "\n",
    "        # --- Datos Bibliográficos (Celda más compleja) ---\n",
    "        bibliography_cell = cells[2]\n",
    "        cell_text = bibliography_cell.get_text(separator=' ', strip=True)\n",
    "\n",
    "        # Título del Artículo (texto entre comillas)\n",
    "        title_match = re.search(r'\"([^\"]+)\"', cell_text)\n",
    "        article_title = title_match.group(1).strip() if title_match else \"No encontrado\"\n",
    "\n",
    "        # Autores (texto antes de la primera comilla)\n",
    "        authors = cell_text.split('\"')[0].strip()\n",
    "\n",
    "        # Inicializar campos de enlaces e IDs\n",
    "        doi_link = \"No encontrado\"\n",
    "        pubmed_link = \"No encontrado\"\n",
    "        pubmed_id = \"No encontrado\"\n",
    "        pmc_link = \"No encontrado\"\n",
    "        pmc_id = \"No encontrado\"\n",
    "\n",
    "        # Buscar todos los enlaces <a> en la celda para extraer sus datos\n",
    "        links_in_cell = bibliography_cell.find_all('a')\n",
    "        for link in links_in_cell:\n",
    "            href = link.get('href', '')\n",
    "            text = link.get_text(strip=True)\n",
    "            \n",
    "            if \"doi.org\" in href:\n",
    "                doi_link = href\n",
    "            elif \"db=pubmed\" in href:\n",
    "                pubmed_link = href\n",
    "                if \"PMID:\" in text:\n",
    "                    pubmed_id = text.replace(\"PMID:\", \"\").strip()\n",
    "            elif \"pmc/articles\" in href:\n",
    "                pmc_link = href\n",
    "                if \"PMCID:\" in text:\n",
    "                    pmc_id = text.replace(\"PMCID:\", \"\").strip()\n",
    "\n",
    "        return {\n",
    "            'PI Name': pi_name,\n",
    "            'Bibliography Last Updated': last_updated,\n",
    "            'Project Name': project_name,\n",
    "            'Project Link': project_link,\n",
    "            'Task ID': task_id,\n",
    "            'Authors': authors,\n",
    "            'Article Title': article_title,\n",
    "            'DOI': doi_link,\n",
    "            'PubMed ID': pubmed_id,\n",
    "            'PubMed Link': pubmed_link,\n",
    "            'PubMed Central ID': pmc_id,\n",
    "            'PubMed Central Link': pmc_link\n",
    "        }\n",
    "    except (AttributeError, IndexError):\n",
    "        return None\n",
    "    \n",
    "def parse_bibliography_results(html_content: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Parsea el contenido HTML de un ÚNICO archivo.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "    results_table = soup.find('table', class_='intro')\n",
    "    \n",
    "    if not results_table:\n",
    "        return []\n",
    "\n",
    "    all_projects = []\n",
    "    current_pi_name = None\n",
    "    current_last_updated = None\n",
    "\n",
    "    for row in results_table.find_all('tr'):\n",
    "        if 'title' in row.get('class', []):\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) >= 5:\n",
    "                current_pi_name = cells[2].get_text(strip=True)\n",
    "                current_last_updated = cells[4].get_text(strip=True)\n",
    "        \n",
    "        elif row.find('a', href=re.compile(\"TASKID\")):\n",
    "            project_data = extract_project_data(row, current_pi_name, current_last_updated)\n",
    "            if project_data:\n",
    "                all_projects.append(project_data)\n",
    "                \n",
    "    return all_projects\n",
    "\n",
    "def process_html_folder(folder_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Procesa todos los archivos HTML en una carpeta y agrega los resultados.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Error: La ruta '{folder_path}' no es un directorio válido.\")\n",
    "        return []\n",
    "        \n",
    "    aggregated_results = []\n",
    "    print(f\"Escaneando directorio: {folder_path}\")\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.html', '.htm')):\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            print(f\"  -> Procesando archivo: {filename}\")\n",
    "            \n",
    "            html_content = read_html_from_file(full_path)\n",
    "            if html_content:\n",
    "                projects_from_file = parse_bibliography_results(html_content)\n",
    "                for project in projects_from_file:\n",
    "                    project['Source File'] = filename\n",
    "                \n",
    "                aggregated_results.extend(projects_from_file)\n",
    "\n",
    "    return aggregated_results\n",
    "\n",
    "def save_results_to_json(project_list: list[dict], output_path: str):\n",
    "    \"\"\"\n",
    "    Guarda una lista de diccionarios en un archivo JSON.\n",
    "\n",
    "    Args:\n",
    "        project_list: La lista de datos de proyectos.\n",
    "        output_path: La ruta del archivo JSON de salida.\n",
    "    \"\"\"\n",
    "    if not project_list:\n",
    "        print(\"No hay datos para guardar en el archivo JSON.\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            # json.dump escribe la lista en el archivo\n",
    "            # indent=4 formatea el archivo para que sea legible\n",
    "            # ensure_ascii=False permite guardar caracteres especiales como acentos\n",
    "            json.dump(project_list, f, indent=4, ensure_ascii=False)\n",
    "        print(f\"\\n¡Éxito! Los resultados se han guardado en: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: No se pudo guardar el archivo JSON. Razón: {e}\")\n",
    "\n",
    "def display_results(project_list: list[dict]):\n",
    "    \"\"\"\n",
    "    Imprime los resultados extraídos en la consola.\n",
    "    \"\"\"\n",
    "    if not project_list:\n",
    "        print(\"No se extrajeron datos para mostrar.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nTotal de registros extraídos: {len(project_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e1b12b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escaneando directorio: taskbook/table_html\n",
      "  -> Procesando archivo: 1.html\n",
      "  -> Procesando archivo: 10.html\n",
      "  -> Procesando archivo: 11.html\n",
      "  -> Procesando archivo: 12.html\n",
      "  -> Procesando archivo: 2.html\n",
      "  -> Procesando archivo: 3.html\n",
      "  -> Procesando archivo: 4.html\n",
      "  -> Procesando archivo: 5.html\n",
      "  -> Procesando archivo: 6.html\n",
      "  -> Procesando archivo: 7.html\n",
      "  -> Procesando archivo: 8.html\n",
      "  -> Procesando archivo: 9.html\n",
      "\n",
      "¡Éxito! Los resultados se han guardado en: taskbook/nasa_tasks.json\n",
      "\n",
      "Total de registros extraídos: 557\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Bloque principal de ejecución ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- MODIFICA ESTA LÍNEA ---\n",
    "    # Pon la ruta a la CARPETA que contiene tus archivos HTML.\n",
    "    folder_path = \"taskbook/table_html\"\n",
    "    output_json_path = \"taskbook/nasa_tasks.json\"\n",
    "    \n",
    "    # 1. Procesar toda la carpeta de archivos HTML\n",
    "    all_extracted_projects = process_html_folder(folder_path)\n",
    "    \n",
    "    # 2. Guardar los resultados combinados en un archivo JSON\n",
    "    save_results_to_json(all_extracted_projects, output_json_path)\n",
    "    \n",
    "    # 3. Mostrar una vista previa de los resultados en la consola\n",
    "    display_results(all_extracted_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a89a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasa_env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
